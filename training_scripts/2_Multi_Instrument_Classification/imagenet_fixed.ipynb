{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Import resnet\n",
    "from torchvision import models\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "import requests\n",
    "import tqdm as tqdm\n",
    "\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "sys.path.append('../../functions')\n",
    "import functions as f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set local path to the folder containing the .wav audio files\n",
    "path = 'C:/Users/lucvo/VScode/Machine_learning/Audio_data/nsynth-valid.jsonwav/nsynth-valid/audio/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lucvo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\lucvo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Load resnet18 model with pretrained weights\n",
    "model = models.resnet18(pretrained=True)\n",
    "\n",
    "# Print model architecture\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_model():\n",
    "    # Load resnet18 model with pretrained weights\n",
    "    model = models.resnet18(pretrained=True)\n",
    "    for param in model.parameters():\n",
    "        param.require_grad = False\n",
    "    model.avgpool = nn.AdaptiveAvgPool2d(output_size=(1, 1))\n",
    "    model.fc = nn.Sequential(\n",
    "      nn.Flatten(),\n",
    "      nn.Linear(512, 128), # 512 for resnet18 or 2048 for resnet 50\n",
    "      nn.ReLU(inplace=True),\n",
    "      nn.Dropout(.2),\n",
    "      nn.Linear(128, 6),\n",
    "      nn.Sigmoid()\n",
    "    )\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "    return model, optimizer\n",
    "\n",
    "def loss_fn(y_pred, y_true):\n",
    "    return torch.sum(torch.abs(y_pred - y_true))/y_pred.shape[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 159.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(80, 1025, 126)\n",
      "(10, 1025, 126)\n",
      "(10, 1025, 126)\n"
     ]
    }
   ],
   "source": [
    "# Run this cell for spectrograms with 3 instruments\n",
    "mixed_spectograms,  labels = f.generate_mixed_spectrograms(100, 3 , path = path)\n",
    "\n",
    "# Split into training, validation and test (80/10/10)\n",
    "X_train, X_val, X_test, y_train, y_val, y_test = f.split_data(mixed_spectograms, labels, 0.1, 0.1)\n",
    "\n",
    "# Print the size of the training, validation and test sets\n",
    "print(X_train.shape)\n",
    "print(X_val.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:04<00:00, 109.36it/s]\n",
      "100%|██████████| 500/500 [00:06<00:00, 81.64it/s]\n",
      "100%|██████████| 500/500 [00:07<00:00, 63.40it/s]\n",
      "100%|██████████| 500/500 [00:08<00:00, 59.42it/s]\n",
      "100%|██████████| 500/500 [00:09<00:00, 55.36it/s]\n",
      "100%|██████████| 500/500 [00:09<00:00, 55.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2400, 1025, 126) (2400, 6)\n",
      "(300, 1025, 126) (300, 6)\n",
      "(300, 1025, 126) (300, 6)\n"
     ]
    }
   ],
   "source": [
    "# Run this cell for spectrograms with varying number of instruments\n",
    "\n",
    "# Create a new training set, with 1000 samples of each class\n",
    "X1, y1 = f.generate_mixed_spectrograms(500, 1, path=path)\n",
    "X2, y2 = f.generate_mixed_spectrograms(500, 2, path=path)\n",
    "X3, y3 = f.generate_mixed_spectrograms(500, 3, path=path)\n",
    "X4, y4 = f.generate_mixed_spectrograms(500, 4, path=path)\n",
    "X5, y5 = f.generate_mixed_spectrograms(500, 5, path=path)\n",
    "X6, y6 = f.generate_mixed_spectrograms(500, 6, path=path)\n",
    "\n",
    "# Add the data to a single test array\n",
    "X_train_multi = np.concatenate((X1, X2, X3, X4, X5, X6))\n",
    "y_train_multi = np.concatenate((y1, y2, y3, y4, y5, y6))\n",
    "\n",
    "# Shuffle the data using numpy\n",
    "shuffled_indices = np.random.permutation(len(y_train_multi))\n",
    "X_train_multi = X_train_multi[shuffled_indices]\n",
    "y_train_multi = y_train_multi[shuffled_indices]\n",
    "\n",
    "# Split into training, validation and test (80/10/10)\n",
    "X_train_multi, X_val_multi, X_test_multi, y_train_multi, y_val_multi, y_test_multi = f.split_data(X_train_multi, y_train_multi, 0.1, 0.1)\n",
    "\n",
    "# Print the shapes of the training, validation and test sets\n",
    "print(X_train_multi.shape, y_train_multi.shape)\n",
    "print(X_val_multi.shape, y_val_multi.shape)\n",
    "print(X_test_multi.shape, y_test_multi.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "# Function to plot spectrogram using librosa\n",
    "\n",
    "def spectrogram_to_rgb(spectrogram, eps=1e-6):\n",
    "    # Min-max scale to fit inside 8-bit RGB\n",
    "    img = 255 * (spectrogram - spectrogram.min()) / (spectrogram.max() - spectrogram.min())\n",
    "    \n",
    "    # Convert to uint8\n",
    "    img = img.astype(np.uint8)\n",
    "    \n",
    "    # Stack the image to create a 3-channel image\n",
    "    img = np.stack([img] * 3, axis=-1)\n",
    "    \n",
    "    return img\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 80/80 [00:00<00:00, 1360.93it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 883.25it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 2789.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(80, 3, 1025, 126)\n",
      "(10, 3, 1025, 126)\n",
      "(10, 3, 1025, 126)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Run this cell if you generated the spectrograms with 3 instruments\n",
    "\n",
    "# Convert X_train_multi, X_val_multi and X_test_multi to RGB images\n",
    "X_train_rgb = []\n",
    "for i in tqdm.tqdm(range(X_train.shape[0])):\n",
    "    rgb_img = spectrogram_to_rgb(X_train[i])\n",
    "    rgb_img = np.moveaxis(rgb_img, 2, 0)\n",
    "    X_train_rgb.append(rgb_img)\n",
    "X_train_rgb = np.array(X_train_rgb)\n",
    "\n",
    "X_val_rgb = []\n",
    "for i in tqdm.tqdm(range(X_val.shape[0])):\n",
    "    rgb_img = spectrogram_to_rgb(X_val[i])\n",
    "    rgb_img = np.moveaxis(rgb_img, 2, 0)\n",
    "    X_val_rgb.append(rgb_img)\n",
    "X_val_rgb = np.array(X_val_rgb)\n",
    "\n",
    "X_test_rgb = []\n",
    "for i in tqdm.tqdm(range(X_test.shape[0])):\n",
    "    rgb_img = spectrogram_to_rgb(X_test[i])\n",
    "    rgb_img = np.moveaxis(rgb_img, 2, 0)\n",
    "    X_test_rgb.append(rgb_img)\n",
    "X_test_rgb = np.array(X_test_rgb)\n",
    "\n",
    "# Print the shapes of the RGB images\n",
    "print(X_train_rgb.shape)\n",
    "print(X_val_rgb.shape)\n",
    "print(X_test_rgb.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2400/2400 [00:02<00:00, 898.86it/s]\n",
      "100%|██████████| 300/300 [00:00<00:00, 849.31it/s]\n",
      "100%|██████████| 300/300 [00:00<00:00, 1201.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2400, 3, 1025, 126)\n",
      "(300, 3, 1025, 126)\n",
      "(300, 3, 1025, 126)\n"
     ]
    }
   ],
   "source": [
    "# Run this cell if you generated the spectrograms with varying number of instruments\n",
    "\n",
    "# Convert X_train_multi, X_val_multi and X_test_multi to RGB images\n",
    "X_train_multi_rgb = []\n",
    "for i in tqdm.tqdm(range(X_train_multi.shape[0])):\n",
    "    rgb_img = spectrogram_to_rgb(X_train_multi[i])\n",
    "    rgb_img = np.moveaxis(rgb_img, 2, 0)\n",
    "    X_train_multi_rgb.append(rgb_img)\n",
    "X_train_multi_rgb = np.array(X_train_multi_rgb)\n",
    "\n",
    "X_val_multi_rgb = []\n",
    "for i in tqdm.tqdm(range(X_val_multi.shape[0])):\n",
    "    rgb_img = spectrogram_to_rgb(X_val_multi[i])\n",
    "    rgb_img = np.moveaxis(rgb_img, 2, 0)\n",
    "    X_val_multi_rgb.append(rgb_img)\n",
    "X_val_multi_rgb = np.array(X_val_multi_rgb)\n",
    "\n",
    "X_test_multi_rgb = []\n",
    "for i in tqdm.tqdm(range(X_test_multi.shape[0])):\n",
    "    rgb_img = spectrogram_to_rgb(X_test_multi[i])\n",
    "    rgb_img = np.moveaxis(rgb_img, 2, 0)\n",
    "    X_test_multi_rgb.append(rgb_img)\n",
    "X_test_multi_rgb = np.array(X_test_multi_rgb)\n",
    "\n",
    "# Print the shapes of the RGB images\n",
    "print(X_train_multi_rgb.shape)\n",
    "print(X_val_multi_rgb.shape)\n",
    "print(X_test_multi_rgb.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([80, 3, 1025, 126])\n",
      "torch.Size([10, 3, 1025, 126])\n",
      "torch.Size([10, 3, 1025, 126])\n"
     ]
    }
   ],
   "source": [
    "# Run this cell if you generated the spectrograms with 3 instruments\n",
    "\n",
    "# Convert the numpy array to a torch tensor\n",
    "X_train_rgb = torch.tensor(X_train_rgb)\n",
    "y_train = torch.tensor(y_train)\n",
    "X_val_rgb = torch.tensor(X_val_rgb)\n",
    "y_val = torch.tensor(y_val)\n",
    "X_test_rgb = torch.tensor(X_test_rgb)\n",
    "y_test = torch.tensor(y_test)\n",
    "\n",
    "# Scale the data to be between 0 and 1\n",
    "def torch_min_max_normalization(X):\n",
    "    X = (X - X.min()) / (X.max() - X.min())\n",
    "    return X\n",
    "\n",
    "X_train_rgb = torch_min_max_normalization(X_train_rgb)\n",
    "X_val_rgb = torch_min_max_normalization(X_val_rgb)\n",
    "X_test_gb = torch_min_max_normalization(X_test_rgb)\n",
    "\n",
    "# Print the shapes of the torch tensors\n",
    "print(X_train_rgb.shape)\n",
    "print(X_val_rgb.shape)\n",
    "print(X_test_rgb.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lucvo\\AppData\\Local\\Temp\\ipykernel_8744\\3827662758.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_train_multi = torch.tensor(y_train_multi)\n",
      "C:\\Users\\lucvo\\AppData\\Local\\Temp\\ipykernel_8744\\3827662758.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_val_multi = torch.tensor(y_val_multi)\n",
      "C:\\Users\\lucvo\\AppData\\Local\\Temp\\ipykernel_8744\\3827662758.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_test_multi = torch.tensor(y_test_multi)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2400, 3, 1025, 126]) torch.Size([2400, 6])\n",
      "torch.Size([300, 3, 1025, 126]) torch.Size([300, 6])\n",
      "torch.Size([300, 3, 1025, 126]) torch.Size([300, 6])\n"
     ]
    }
   ],
   "source": [
    "# Convert the numpy array to a torch tensor\n",
    "X_train_multi_rgb = torch.tensor(X_train_multi_rgb)\n",
    "y_train_multi = torch.tensor(y_train_multi)\n",
    "X_val_multi_rgb = torch.tensor(X_val_multi_rgb)\n",
    "y_val_multi = torch.tensor(y_val_multi)\n",
    "X_test_multi_rgb = torch.tensor(X_test_multi_rgb)\n",
    "y_test_multi = torch.tensor(y_test_multi)\n",
    "\n",
    "# Scale the data to be between 0 and 1\n",
    "def torch_min_max_normalization(X):\n",
    "    X = (X - X.min()) / (X.max() - X.min())\n",
    "    return X\n",
    "\n",
    "X_train_multi_rgb = torch_min_max_normalization(X_train_multi_rgb)\n",
    "X_val_multi_rgb = torch_min_max_normalization(X_val_multi_rgb)\n",
    "X_test_multi_rgb = torch_min_max_normalization(X_test_multi_rgb)\n",
    "\n",
    "# Print the shapes of the torch tensors\n",
    "print(X_train_multi_rgb.shape)\n",
    "print(X_val_multi_rgb.shape)\n",
    "print(X_test_multi_rgb.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lucvo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\lucvo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100, Train Loss: 2.9955, Train Accuracy: 0.5188, Val Loss: 3.0320, Val Accuracy: 0.4000\n",
      "[0.53 0.48 0.46 0.5  0.51 0.47]\n",
      "[1. 1. 0. 0. 1. 0.]\n",
      "\n",
      "Epoch 2/100, Train Loss: 2.8260, Train Accuracy: 0.7333, Val Loss: 3.0342, Val Accuracy: 0.3833\n",
      "[0.51 0.51 0.41 0.44 0.52 0.45]\n",
      "[1. 1. 0. 0. 1. 0.]\n",
      "\n",
      "Epoch 3/100, Train Loss: 2.7043, Train Accuracy: 0.7729, Val Loss: 3.0237, Val Accuracy: 0.4167\n",
      "[0.54 0.51 0.45 0.46 0.55 0.47]\n",
      "[1. 1. 0. 0. 1. 0.]\n",
      "\n",
      "Epoch 4/100, Train Loss: 2.5990, Train Accuracy: 0.8000, Val Loss: 3.0114, Val Accuracy: 0.5333\n",
      "[0.55 0.49 0.43 0.4  0.56 0.43]\n",
      "[1. 1. 0. 0. 1. 0.]\n",
      "\n",
      "Epoch 5/100, Train Loss: 2.5169, Train Accuracy: 0.8250, Val Loss: 3.0113, Val Accuracy: 0.5167\n",
      "[0.53 0.44 0.41 0.4  0.59 0.45]\n",
      "[1. 1. 0. 0. 1. 0.]\n",
      "\n",
      "Epoch 6/100, Train Loss: 2.4280, Train Accuracy: 0.8500, Val Loss: 3.0107, Val Accuracy: 0.5000\n",
      "[0.56 0.48 0.48 0.33 0.6  0.41]\n",
      "[1. 1. 0. 0. 1. 0.]\n",
      "\n",
      "Epoch 7/100, Train Loss: 2.3312, Train Accuracy: 0.8542, Val Loss: 3.0066, Val Accuracy: 0.5333\n",
      "[0.59 0.5  0.48 0.3  0.65 0.42]\n",
      "[1. 1. 0. 0. 1. 0.]\n",
      "\n",
      "Epoch 8/100, Train Loss: 2.2663, Train Accuracy: 0.8562, Val Loss: 2.9965, Val Accuracy: 0.5333\n",
      "[0.52 0.44 0.47 0.33 0.67 0.36]\n",
      "[1. 1. 0. 0. 1. 0.]\n",
      "\n",
      "Epoch 9/100, Train Loss: 2.1937, Train Accuracy: 0.8604, Val Loss: 2.9872, Val Accuracy: 0.5167\n",
      "[0.52 0.43 0.4  0.36 0.61 0.39]\n",
      "[1. 1. 0. 0. 1. 0.]\n",
      "\n",
      "Epoch 10/100, Train Loss: 2.1521, Train Accuracy: 0.8750, Val Loss: 2.9779, Val Accuracy: 0.5833\n",
      "[0.53 0.43 0.48 0.31 0.71 0.35]\n",
      "[1. 1. 0. 0. 1. 0.]\n",
      "\n",
      "Epoch 11/100, Train Loss: 2.0624, Train Accuracy: 0.8854, Val Loss: 2.9682, Val Accuracy: 0.5667\n",
      "[0.53 0.43 0.49 0.26 0.72 0.38]\n",
      "[1. 1. 0. 0. 1. 0.]\n",
      "\n",
      "Epoch 12/100, Train Loss: 1.9785, Train Accuracy: 0.9000, Val Loss: 2.9597, Val Accuracy: 0.5500\n",
      "[0.56 0.42 0.5  0.31 0.72 0.35]\n",
      "[1. 1. 0. 0. 1. 0.]\n",
      "\n",
      "Epoch 13/100, Train Loss: 1.9509, Train Accuracy: 0.9042, Val Loss: 2.9534, Val Accuracy: 0.5500\n",
      "[0.56 0.45 0.45 0.19 0.79 0.37]\n",
      "[1. 1. 0. 0. 1. 0.]\n",
      "\n",
      "Epoch 14/100, Train Loss: 1.8518, Train Accuracy: 0.9021, Val Loss: 2.9494, Val Accuracy: 0.5667\n",
      "[0.53 0.43 0.48 0.24 0.76 0.34]\n",
      "[1. 1. 0. 0. 1. 0.]\n",
      "\n",
      "Epoch 15/100, Train Loss: 1.8405, Train Accuracy: 0.9062, Val Loss: 2.9460, Val Accuracy: 0.5833\n",
      "[0.58 0.42 0.43 0.17 0.83 0.26]\n",
      "[1. 1. 0. 0. 1. 0.]\n",
      "\n",
      "Epoch 16/100, Train Loss: 1.7578, Train Accuracy: 0.9042, Val Loss: 2.9470, Val Accuracy: 0.5833\n",
      "[0.56 0.43 0.42 0.14 0.8  0.27]\n",
      "[1. 1. 0. 0. 1. 0.]\n",
      "\n",
      "Epoch 17/100, Train Loss: 1.6753, Train Accuracy: 0.9354, Val Loss: 2.9468, Val Accuracy: 0.5833\n",
      "[0.52 0.54 0.44 0.25 0.79 0.25]\n",
      "[1. 1. 0. 0. 1. 0.]\n",
      "\n",
      "Epoch 18/100, Train Loss: 1.6757, Train Accuracy: 0.9146, Val Loss: 2.9462, Val Accuracy: 0.5833\n",
      "[0.55 0.41 0.34 0.24 0.72 0.35]\n",
      "[1. 1. 0. 0. 1. 0.]\n",
      "\n",
      "Epoch 19/100, Train Loss: 1.5823, Train Accuracy: 0.9333, Val Loss: 2.9439, Val Accuracy: 0.5667\n",
      "[0.66 0.44 0.39 0.14 0.86 0.26]\n",
      "[1. 1. 0. 0. 1. 0.]\n",
      "\n",
      "Epoch 20/100, Train Loss: 1.5275, Train Accuracy: 0.9542, Val Loss: 2.9412, Val Accuracy: 0.5667\n",
      "[0.54 0.52 0.43 0.12 0.85 0.18]\n",
      "[1. 1. 0. 0. 1. 0.]\n",
      "\n",
      "Epoch 21/100, Train Loss: 1.5028, Train Accuracy: 0.9396, Val Loss: 2.9392, Val Accuracy: 0.6000\n",
      "[0.61 0.47 0.45 0.13 0.86 0.24]\n",
      "[1. 1. 0. 0. 1. 0.]\n",
      "\n",
      "Epoch 22/100, Train Loss: 1.4166, Train Accuracy: 0.9479, Val Loss: 2.9349, Val Accuracy: 0.6000\n",
      "[0.59 0.39 0.37 0.12 0.87 0.2 ]\n",
      "[1. 1. 0. 0. 1. 0.]\n",
      "\n",
      "Epoch 23/100, Train Loss: 1.3942, Train Accuracy: 0.9521, Val Loss: 2.9231, Val Accuracy: 0.5833\n",
      "[0.66 0.53 0.38 0.14 0.84 0.29]\n",
      "[1. 1. 0. 0. 1. 0.]\n",
      "\n",
      "Epoch 24/100, Train Loss: 1.2987, Train Accuracy: 0.9604, Val Loss: 2.9099, Val Accuracy: 0.6000\n",
      "[0.65 0.59 0.31 0.13 0.89 0.14]\n",
      "[1. 1. 0. 0. 1. 0.]\n",
      "\n",
      "Epoch 25/100, Train Loss: 1.2931, Train Accuracy: 0.9729, Val Loss: 2.8961, Val Accuracy: 0.6167\n",
      "[0.65 0.56 0.28 0.13 0.85 0.22]\n",
      "[1. 1. 0. 0. 1. 0.]\n",
      "\n",
      "Epoch 26/100, Train Loss: 1.2574, Train Accuracy: 0.9604, Val Loss: 2.8821, Val Accuracy: 0.6167\n",
      "[0.72 0.43 0.32 0.14 0.83 0.21]\n",
      "[1. 1. 0. 0. 1. 0.]\n",
      "\n",
      "Epoch 27/100, Train Loss: 1.1878, Train Accuracy: 0.9625, Val Loss: 2.8695, Val Accuracy: 0.6167\n",
      "[0.69 0.74 0.34 0.2  0.79 0.19]\n",
      "[1. 1. 0. 0. 1. 0.]\n",
      "\n",
      "Epoch 28/100, Train Loss: 1.1423, Train Accuracy: 0.9875, Val Loss: 2.8573, Val Accuracy: 0.6333\n",
      "[0.57 0.58 0.27 0.1  0.87 0.23]\n",
      "[1. 1. 0. 0. 1. 0.]\n",
      "\n",
      "Epoch 29/100, Train Loss: 1.0873, Train Accuracy: 0.9896, Val Loss: 2.8410, Val Accuracy: 0.6333\n",
      "[0.63 0.6  0.33 0.17 0.84 0.18]\n",
      "[1. 1. 0. 0. 1. 0.]\n",
      "\n",
      "Epoch 30/100, Train Loss: 1.0450, Train Accuracy: 0.9854, Val Loss: 2.8257, Val Accuracy: 0.6167\n",
      "[0.55 0.73 0.24 0.12 0.84 0.18]\n",
      "[1. 1. 0. 0. 1. 0.]\n",
      "\n",
      "Epoch 31/100, Train Loss: 0.9922, Train Accuracy: 0.9896, Val Loss: 2.8135, Val Accuracy: 0.6167\n",
      "[0.69 0.75 0.33 0.1  0.9  0.15]\n",
      "[1. 1. 0. 0. 1. 0.]\n",
      "\n",
      "Epoch 32/100, Train Loss: 1.0050, Train Accuracy: 0.9896, Val Loss: 2.7983, Val Accuracy: 0.6333\n",
      "[0.86 0.81 0.22 0.19 0.83 0.17]\n",
      "[1. 1. 0. 0. 1. 0.]\n",
      "\n",
      "Epoch 33/100, Train Loss: 0.9503, Train Accuracy: 0.9958, Val Loss: 2.7891, Val Accuracy: 0.6167\n",
      "[0.67 0.78 0.16 0.12 0.87 0.12]\n",
      "[1. 1. 0. 0. 1. 0.]\n",
      "\n",
      "Epoch 34/100, Train Loss: 0.8842, Train Accuracy: 0.9958, Val Loss: 2.7833, Val Accuracy: 0.6167\n",
      "[0.65 0.82 0.19 0.07 0.95 0.11]\n",
      "[1. 1. 0. 0. 1. 0.]\n",
      "\n",
      "Epoch 35/100, Train Loss: 0.8505, Train Accuracy: 0.9979, Val Loss: 2.7708, Val Accuracy: 0.6167\n",
      "[0.71 0.84 0.17 0.08 0.93 0.06]\n",
      "[1. 1. 0. 0. 1. 0.]\n",
      "\n",
      "Epoch 36/100, Train Loss: 0.8349, Train Accuracy: 1.0000, Val Loss: 2.7557, Val Accuracy: 0.6333\n",
      "[0.7  0.84 0.18 0.14 0.75 0.12]\n",
      "[1. 1. 0. 0. 1. 0.]\n",
      "\n",
      "Epoch 37/100, Train Loss: 0.8284, Train Accuracy: 0.9979, Val Loss: 2.7406, Val Accuracy: 0.6500\n",
      "[0.91 0.82 0.15 0.12 0.93 0.14]\n",
      "[1. 1. 0. 0. 1. 0.]\n",
      "\n",
      "Epoch 38/100, Train Loss: 0.7489, Train Accuracy: 0.9958, Val Loss: 2.7261, Val Accuracy: 0.6500\n",
      "[0.89 0.9  0.12 0.08 0.93 0.04]\n",
      "[1. 1. 0. 0. 1. 0.]\n",
      "\n",
      "Epoch 39/100, Train Loss: 0.7226, Train Accuracy: 1.0000, Val Loss: 2.7098, Val Accuracy: 0.6500\n",
      "[0.87 0.82 0.08 0.11 0.95 0.06]\n",
      "[1. 1. 0. 0. 1. 0.]\n",
      "\n",
      "Epoch 40/100, Train Loss: 0.6796, Train Accuracy: 1.0000, Val Loss: 2.6922, Val Accuracy: 0.6333\n",
      "[0.78 0.8  0.09 0.17 0.82 0.19]\n",
      "[1. 1. 0. 0. 1. 0.]\n",
      "\n",
      "Epoch 41/100, Train Loss: 0.6550, Train Accuracy: 1.0000, Val Loss: 2.6757, Val Accuracy: 0.6500\n",
      "[0.87 0.9  0.15 0.08 0.93 0.12]\n",
      "[1. 1. 0. 0. 1. 0.]\n",
      "\n",
      "Epoch 42/100, Train Loss: 0.6168, Train Accuracy: 1.0000, Val Loss: 2.6525, Val Accuracy: 0.6500\n",
      "[0.93 0.93 0.12 0.09 0.83 0.03]\n",
      "[1. 1. 0. 0. 1. 0.]\n",
      "\n",
      "Epoch 43/100, Train Loss: 0.5923, Train Accuracy: 1.0000, Val Loss: 2.6354, Val Accuracy: 0.6667\n",
      "[0.85 0.92 0.13 0.1  0.83 0.03]\n",
      "[1. 1. 0. 0. 1. 0.]\n",
      "\n",
      "Epoch 44/100, Train Loss: 0.5696, Train Accuracy: 1.0000, Val Loss: 2.6205, Val Accuracy: 0.6333\n",
      "[0.91 0.86 0.05 0.08 0.97 0.08]\n",
      "[1. 1. 0. 0. 1. 0.]\n",
      "\n",
      "Epoch 45/100, Train Loss: 0.5530, Train Accuracy: 1.0000, Val Loss: 2.6184, Val Accuracy: 0.6167\n",
      "[0.92 0.91 0.11 0.11 0.95 0.09]\n",
      "[1. 1. 0. 0. 1. 0.]\n",
      "\n",
      "Epoch 46/100, Train Loss: 0.5063, Train Accuracy: 1.0000, Val Loss: 2.6132, Val Accuracy: 0.6000\n",
      "[0.88 0.85 0.08 0.12 0.96 0.06]\n",
      "[1. 1. 0. 0. 1. 0.]\n",
      "\n",
      "Epoch 47/100, Train Loss: 0.5273, Train Accuracy: 1.0000, Val Loss: 2.6065, Val Accuracy: 0.6000\n",
      "[0.91 0.89 0.17 0.04 0.97 0.07]\n",
      "[1. 1. 0. 0. 1. 0.]\n",
      "\n",
      "Epoch 48/100, Train Loss: 0.4828, Train Accuracy: 1.0000, Val Loss: 2.5990, Val Accuracy: 0.6000\n",
      "[0.9  0.94 0.06 0.04 0.92 0.04]\n",
      "[1. 1. 0. 0. 1. 0.]\n",
      "\n",
      "Epoch 49/100, Train Loss: 0.4702, Train Accuracy: 1.0000, Val Loss: 2.6019, Val Accuracy: 0.6167\n",
      "[0.93 0.92 0.05 0.03 0.98 0.04]\n",
      "[1. 1. 0. 0. 1. 0.]\n",
      "\n",
      "Epoch 50/100, Train Loss: 0.4665, Train Accuracy: 1.0000, Val Loss: 2.5959, Val Accuracy: 0.6167\n",
      "[0.86 0.79 0.13 0.01 0.96 0.04]\n",
      "[1. 1. 0. 0. 1. 0.]\n",
      "\n",
      "Epoch 51/100, Train Loss: 0.4478, Train Accuracy: 1.0000, Val Loss: 2.5813, Val Accuracy: 0.6167\n",
      "[0.88 0.87 0.06 0.04 0.94 0.05]\n",
      "[1. 1. 0. 0. 1. 0.]\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[99], line 59\u001b[0m\n\u001b[0;32m     55\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model, train_loss, train_acc, val_loss, val_acc\n\u001b[0;32m     58\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[1;32m---> 59\u001b[0m trained_model, train_loss, train_acc, val_loss, val_acc \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train_rgb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_val_rgb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpatience\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[99], line 21\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(model, x_train, y_train, x_val, y_val, optimizer, loss_fn, num_epochs, patience)\u001b[0m\n\u001b[0;32m     19\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m     20\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m---> 21\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     22\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_fn(y_pred, y_train)\n\u001b[0;32m     23\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[1;32mc:\\Users\\lucvo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\lucvo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\lucvo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\models\\resnet.py:285\u001b[0m, in \u001b[0;36mResNet.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 285\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_forward_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\lucvo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\models\\resnet.py:271\u001b[0m, in \u001b[0;36mResNet._forward_impl\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    269\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbn1(x)\n\u001b[0;32m    270\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu(x)\n\u001b[1;32m--> 271\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmaxpool\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    273\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer1(x)\n\u001b[0;32m    274\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer2(x)\n",
      "File \u001b[1;32mc:\\Users\\lucvo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\lucvo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\lucvo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\pooling.py:164\u001b[0m, in \u001b[0;36mMaxPool2d.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    163\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor):\n\u001b[1;32m--> 164\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_pool2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkernel_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    165\u001b[0m \u001b[43m                        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mceil_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mceil_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    166\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mreturn_indices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreturn_indices\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\lucvo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\_jit_internal.py:499\u001b[0m, in \u001b[0;36mboolean_dispatch.<locals>.fn\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    497\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m if_true(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    498\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 499\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mif_false\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\lucvo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\functional.py:796\u001b[0m, in \u001b[0;36m_max_pool2d\u001b[1;34m(input, kernel_size, stride, padding, dilation, ceil_mode, return_indices)\u001b[0m\n\u001b[0;32m    794\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m stride \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    795\u001b[0m     stride \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39mannotate(List[\u001b[38;5;28mint\u001b[39m], [])\n\u001b[1;32m--> 796\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_pool2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkernel_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mceil_mode\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Define the model\n",
    "model, optimizer = get_model()\n",
    "\n",
    "def get_accuracy(y_pred, y_true):\n",
    "    y_pred = y_pred.detach().numpy()\n",
    "    y_true = y_true.detach().numpy()\n",
    "    y_pred = np.round(y_pred)\n",
    "    accuracy = np.mean(y_pred == y_true)\n",
    "    return accuracy\n",
    "\n",
    "# Function to train the model\n",
    "def train_model(model, x_train, y_train, x_val, y_val, optimizer, loss_fn, num_epochs=100, patience = 5):\n",
    "    train_loss = []\n",
    "    train_acc = []\n",
    "    val_loss = []\n",
    "    val_acc = []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = model(x_train)\n",
    "        loss = loss_fn(y_pred, y_train)\n",
    "        loss.backward()\n",
    "        train_loss.append(loss.item())\n",
    "\n",
    "        # Compute the accuracy\n",
    "        accuracy = get_accuracy(y_pred, y_train)\n",
    "        train_acc.append(accuracy)\n",
    "\n",
    "        # Compute the validation loss and accuracy\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            y_pred_val = model(x_val)\n",
    "            val_loss.append(loss_fn(y_pred_val, y_val).item())\n",
    "            val_accuracy = get_accuracy(y_pred_val, y_val)\n",
    "            val_acc.append(val_accuracy)\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        # Convert y_pred to np array, round to 2 decimal places\n",
    "        y_pred = y_pred.detach().numpy().round(2)\n",
    "        y_labels = y_train.detach().numpy()\n",
    "        print(f\"Epoch {epoch + 1}/{num_epochs}, Train Loss: {loss.item():.4f}, Train Accuracy: {accuracy:.4f}, Val Loss: {val_loss[-1]:.4f}, Val Accuracy: {val_accuracy:.4f}\")\n",
    "        print(y_pred[0])\n",
    "        print(y_labels[0])\n",
    "        print(\"\")\n",
    "\n",
    "        # Include early stopping\n",
    "        if epoch > patience:\n",
    "            if val_loss[-patience] <= min(val_loss):\n",
    "                print(\"Early stopping activated\")\n",
    "                break\n",
    "\n",
    "\n",
    "    return model, train_loss, train_acc, val_loss, val_acc\n",
    "\n",
    "\n",
    "# Train the model\n",
    "trained_model, train_loss, train_acc, val_loss, val_acc = train_model(model, X_train_rgb, y_train, X_val_rgb, y_val, optimizer, loss_fn, num_epochs=100, patience = 5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_loss' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[101], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Plot the training and validation loss as a function of the epoch\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(\u001b[43mtrain_loss\u001b[49m, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain loss\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      3\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(val_loss, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalidation loss\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      4\u001b[0m plt\u001b[38;5;241m.\u001b[39mxlabel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpoch\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_loss' is not defined"
     ]
    }
   ],
   "source": [
    "# Plot the training and validation loss as a function of the epoch\n",
    "plt.plot(train_loss, label='train loss')\n",
    "plt.plot(val_loss, label='validation loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Plot the training and validation accuracy as a function of the epoch\n",
    "plt.plot(train_acc, label='train accuracy')\n",
    "plt.plot(val_acc, label='validation accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "trained_model.eval()\n",
    "with torch.no_grad():\n",
    "    y_pred_test = trained_model(X_test_rgb)\n",
    "    test_loss = loss_fn(y_pred_test, y_test)\n",
    "    test_accuracy = get_accuracy(y_pred_test, y_test)\n",
    "    print(f\"Test Loss: {test_loss.item():.4f}, Test Accuracy: {test_accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
